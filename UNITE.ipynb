{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbmeSoy6C9Ux"
      },
      "source": [
        "데이터셋은 우선적으로는 CelebDFV2를 사용하고, 이후에 GTA-V 데이터를 합쳐보도록 하자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpBO_bgZCCur"
      },
      "source": [
        "이걸 어디부터 구현해야 할까...\n",
        "\n",
        "일단 SigLIP을 불러오는 것부터 시작하자. Quantize를 해줘서 최대한 부담을 줄여주자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NPK-Ap0dOit",
        "outputId": "ed0d983b-4bb4-49fd-be76-a059cc406eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m28 packages\u001b[0m \u001b[2min 1.06s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 9.86s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflash-attn\u001b[0m\u001b[2m==2.8.3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install --system flash-attn --no-build-isolation\n",
        "!pip install -q flash-attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvXKooN5CCOG",
        "outputId": "04a1dcda-185e-4fe0-ba1f-c58f39b6a34c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m43 packages\u001b[0m \u001b[2min 271ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 82ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlightning\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.15.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytorch-lightning\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.8.2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install --system lightning\n",
        "!pip install -q lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le5t6iy32IYI",
        "outputId": "d5b0a959-11ee-47e5-ed6f-b27ac98984d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            " V..... av1_cuvid            Nvidia CUVID AV1 decoder (codec av1)\n",
            " V..... h264_cuvid           Nvidia CUVID H264 decoder (codec h264)\n",
            " V..... hevc_cuvid           Nvidia CUVID HEVC decoder (codec hevc)\n",
            " V..... mjpeg_cuvid          Nvidia CUVID MJPEG decoder (codec mjpeg)\n",
            " V..... mpeg1_cuvid          Nvidia CUVID MPEG1VIDEO decoder (codec mpeg1video)\n",
            " V..... mpeg2_cuvid          Nvidia CUVID MPEG2VIDEO decoder (codec mpeg2video)\n",
            " V..... mpeg4_cuvid          Nvidia CUVID MPEG4 decoder (codec mpeg4)\n",
            " V..... vc1_cuvid            Nvidia CUVID VC1 decoder (codec vc1)\n",
            " V..... vp8_cuvid            Nvidia CUVID VP8 decoder (codec vp8)\n",
            " V..... vp9_cuvid            Nvidia CUVID VP9 decoder (codec vp9)\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -decoders | grep -i nvidia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5NX_61lI4WV",
        "outputId": "8146b914-e612-49a6-f0a0-7c42a358ce02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m29 packages\u001b[0m \u001b[2min 47ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 685ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.49.1\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install --system bitsandbytes\n",
        "!pip install -q bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PVC-h-3x9aO",
        "outputId": "8a7e6a99-5e0f-4bd2-f85e-7d749c435d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 940ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 43ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchcodec\u001b[0m\u001b[2m==0.9.0+cu126\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install --force-reinstall torchcodec==0.9.0 --index-url=https://download.pytorch.org/whl/cu126"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CesM4HbVBZWY"
      },
      "outputs": [],
      "source": [
        "import lightning.pytorch as L\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, AutoModel, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1LPodHaYK4c"
      },
      "source": [
        "embed_size = 768\n",
        "\n",
        "frame_token = 576"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZwnOwZsXtZR"
      },
      "source": [
        "솔직히, 왠만하면 원본 모델을 따라가고 싶지만... 일단 인코더를 더 경량으로 바꾼다.\n",
        "\n",
        "나중에 성능 안 나오면 탓할 것 중 인코더가 늘었다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cTmv1qBoXnHs"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0p36S4LXYIzn"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from flash_attn import flash_attn_func\n",
        "\n",
        "class ViTEncoder(nn.Module):\n",
        "    def __init__(self, embed_size=768, num_heads=12, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_size // num_heads\n",
        "        assert self.head_dim * num_heads == embed_size, \"embed_size must be divisible by num_heads\"\n",
        "\n",
        "        self.q_proj = nn.Linear(embed_size, embed_size)\n",
        "        self.k_proj = nn.Linear(embed_size, embed_size)\n",
        "        self.v_proj = nn.Linear(embed_size, embed_size)\n",
        "        self.out_proj = nn.Linear(embed_size, embed_size)\n",
        "        self.dropout_p = dropout\n",
        "\n",
        "        self.ln1 = nn.LayerNorm(embed_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_size, 4 * embed_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(4 * embed_size, embed_size),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.ln2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "    def forward(self, x, return_attn_output=False):\n",
        "        # x: (batch * frames, token/frame, embed_size)\n",
        "        batch_size, frame_token, embed_size = x.shape\n",
        "\n",
        "        # Project queries, keys, values\n",
        "        q = self.q_proj(x) # (batch * frames, token/frame, embed_size)\n",
        "        k = self.k_proj(x) # (batch * frames, token/frame, embed_size)\n",
        "        v = self.v_proj(x) # (batch * frames, token/frame, embed_size)\n",
        "\n",
        "        # Split into multiple heads\n",
        "        q = q.view(batch_size, frame_token, self.num_heads, self.head_dim) # (batch * frames, token/frame, num_heads, head_dim)\n",
        "        k = k.view(batch_size, frame_token, self.num_heads, self.head_dim) # (batch * frames, token/frame, num_heads, head_dim)\n",
        "        v = v.view(batch_size, frame_token, self.num_heads, self.head_dim) # (batch * frames, token/frame, num_heads, head_dim)\n",
        "\n",
        "        # Apply scaled dot product attention\n",
        "        # dropout_p는 훈련 중일 때만 적용\n",
        "        attn_output_raw = flash_attn_func(\n",
        "            q, k, v,\n",
        "            dropout_p=self.dropout_p if self.training else 0.0,\n",
        "            softmax_scale=None, # None이면 1/sqrt(head_dim) 자동 적용\n",
        "            causal=False\n",
        "        )\n",
        "        # attn_output: (batch * frames, token/frame, num_heads, head_dim)\n",
        "\n",
        "        # Concatenate heads and apply final linear projection\n",
        "        attn_output = attn_output_raw.contiguous().view(batch_size, frame_token, embed_size)\n",
        "        attn_output = self.out_proj(attn_output) # (batch_size, seq_len, embed_size)\n",
        "\n",
        "\n",
        "        x = self.ln1(x + attn_output) # Residual connection + LayerNorm\n",
        "        x = self.ln2(x + self.mlp(x))\n",
        "\n",
        "        if return_attn_output:\n",
        "            return x, attn_output_raw\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IA7_g3dQb3rI"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "class TemporalPositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 32, dropout: float = 0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            d_model: Feature dimension (ds = 768)\n",
        "            max_len: Maximum number of frames (nf = 32)\n",
        "            dropout: Dropout probability\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # 1. Frame Index (j) 생성: 0 ~ max_len-1\n",
        "        # 논문의 'j'에 해당합니다.\n",
        "        position = torch.arange(max_len).unsqueeze(1).float()  # [max_len, 1]\n",
        "\n",
        "        # 2. Div Term 계산 (논문 Eq 1의 분모 부분)\n",
        "        # 10000^(2i/ds) 부분을 로그 스케일로 계산\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # 3. PE Matrix 초기화 [max_len, d_model]\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # 4. 논문 수식 (Eq 1) 적용\n",
        "        # PE(j, 2i) = sin(...) -> 짝수 인덱스\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        # PE(j, 2i+1) = cos(...) -> 홀수 인덱스\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # 5. 차원 확장 (Broadcasting 준비)\n",
        "        # PE는 [Frame, Dim] 정보를 담고 있습니다.\n",
        "        # 입력 x: [Batch, Frames, Tokens, Dim]\n",
        "        # PE  : [1,     Frames, 1,      Dim] 형태로 만들어야\n",
        "        # Batch와 Tokens 차원으로 자동 확장(Broadcast)되어 더해집니다.\n",
        "        pe = pe.unsqueeze(0).unsqueeze(2)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: [Batch, Frames, Tokens, Dim]\n",
        "               (예: [B, 32, 576, 768])\n",
        "        Returns:\n",
        "            x: Temporal PE가 더해진 텐서\n",
        "        \"\"\"\n",
        "        # 입력된 비디오의 실제 프레임 수만큼만 PE를 잘라서 사용\n",
        "        current_frames = x.size(1)\n",
        "\n",
        "        # x에 PE를 더함.\n",
        "        # pe[:, :current_frames, :, :]의 shape은 [1, F, 1, D]\n",
        "        # x의 shape [B, F, T, D]에 맞춰서,\n",
        "        # 같은 프레임(F)에 있는 모든 토큰(T)들에게 동일한 PE 벡터가 더해짐.\n",
        "        x = x + self.pe[:, :current_frames, :, :]\n",
        "\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fx_U3LxUoMqM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "class GPUSigLIPProcessor:\n",
        "    def __init__(self, processor):\n",
        "        config = processor.image_processor\n",
        "\n",
        "        # 1. 리사이즈 설정: Bilinear + Antialias=True가 핵심\n",
        "        # Fast 프로세서가 텐서를 처리할 때 사용하는 로직과 일치시킵니다.\n",
        "        self.resize = v2.Resize(\n",
        "            size=(config.size['height'], config.size['width']),\n",
        "            interpolation=v2.InterpolationMode.BILINEAR, # resample=2\n",
        "            antialias=True # 오차를 줄이는 가장 중요한 설정\n",
        "        )\n",
        "\n",
        "        # 2. 정규화 설정\n",
        "        # (x - 0.5) / 0.5 연산\n",
        "        self.mean = torch.tensor(config.image_mean).view(1, 3, 1, 1)\n",
        "        self.std = torch.tensor(config.image_std).view(1, 3, 1, 1)\n",
        "        self.rescale_factor = config.rescale_factor\n",
        "\n",
        "    def __call__(self, video_tensor):\n",
        "        \"\"\"\n",
        "        video_tensor: (B, 3, T, H, W), uint8, GPU\n",
        "        \"\"\"\n",
        "        b, c, t, h, w = video_tensor.shape\n",
        "        device = video_tensor.device\n",
        "\n",
        "        # 차원 변경 (B*T, C, H, W)\n",
        "        x = video_tensor.permute(0, 2, 1, 3, 4)\n",
        "        x = x.flatten(0, 1)\n",
        "\n",
        "        # [Step 1] Resize (uint8 상태에서 수행하거나 float32에서 수행)\n",
        "        # torchvision v2는 uint8 입력을 받아 내부적으로 고정밀 연산을 수행합니다.\n",
        "        x = self.resize(x)\n",
        "\n",
        "        # [Step 2] Float32 변환 및 Rescale (0~255 -> 0~1)\n",
        "        x = x.to(torch.float32) * self.rescale_factor\n",
        "\n",
        "        # [Step 3] Normalize (x - 0.5) / 0.5\n",
        "        # mean, std를 캐싱하여 속도 최적화\n",
        "        self.mean = self.mean.to(device)\n",
        "        self.std = self.std.to(device)\n",
        "        x = (x - self.mean) / self.std\n",
        "\n",
        "        # [Step 4] 최종 모델 입력형태인 float16으로 반환\n",
        "        return x.to(torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dl5XX6bXbf46"
      },
      "outputs": [],
      "source": [
        "class UNITE(nn.Module):\n",
        "    def __init__(\n",
        "            self, num_channel=3, num_cls=2, num_heads=12, max_len=32, dropout=0.1,\n",
        "            encoder_model=\"google/siglip2-base-patch16-384\", use_bfloat=True, cpu_preprocess=True\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        dtype = torch.bfloat16 if use_bfloat else torch.float16\n",
        "        self.vis_encoder = AutoModel.from_pretrained(\n",
        "            encoder_model,\n",
        "            device_map=\"auto\",\n",
        "            dtype=dtype,\n",
        "            attn_implementation=\"flash_attention_2\",\n",
        "        )\n",
        "        self.embed_size = self.vis_encoder.config.vision_config.hidden_size\n",
        "        processor = AutoProcessor.from_pretrained(encoder_model, use_fast=True)\n",
        "        self.processor = GPUSigLIPProcessor(processor)\n",
        "        self.num_heads = num_heads\n",
        "        self.cpu_preprocess = cpu_preprocess\n",
        "\n",
        "        for para in self.vis_encoder.parameters():\n",
        "            para.requires_grad = False\n",
        "        self.vis_encoder.eval()\n",
        "\n",
        "        self.class_token = nn.Parameter(torch.randn((self.embed_size,)), requires_grad=True)\n",
        "\n",
        "        self.pos_embedding = TemporalPositionalEncoding(self.embed_size, max_len)\n",
        "        self.first_encoder = ViTEncoder(self.embed_size, num_heads, dropout)\n",
        "        self.encoders = nn.ModuleList([ViTEncoder(self.embed_size, num_heads, dropout) for _ in range(3)])\n",
        "        self.mlp_head = nn.Linear(self.embed_size, num_cls)\n",
        "\n",
        "\n",
        "    def forward(self, x, return_ad_param=False, return_embed=False):\n",
        "        self.vis_encoder.eval()\n",
        "\n",
        "        # Input: [batch, c, frame, h, w]\n",
        "        b, _, f, *_ = x.shape\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if self.cpu_preprocess:\n",
        "                x = x.permute(0, 2, 1, 3, 4).flatten(0, 1) # (B, C, F, H, W) -> (B*F, C, H, W)\n",
        "                x = x.to(self.vis_encoder.dtype)\n",
        "            else:\n",
        "                # -> Preprocessing [batch * frame, c, h, w]\n",
        "                x = self.processor(x)\n",
        "            # -> Visual encoding [batch * frame, token/frame(576), dim/token (embed_size)]\n",
        "            x = self.vis_encoder.vision_model(pixel_values=x).last_hidden_state\n",
        "        # -> [batch, frame, token/frame, dim/token]\n",
        "        x = x.reshape(b, f, -1, self.embed_size)\n",
        "        x = self.pos_embedding(x)\n",
        "        train_in = x # xi: [batch, frame, token/frame, dim/token]\n",
        "\n",
        "        _, _, t, d = x.shape\n",
        "        # Reshape for transformer\n",
        "        # -> [batch * frame, token/frame, dim/token]\n",
        "        x = x.reshape(b*f, t, d)\n",
        "        # Add class token [batch*frame, 1, dim/token]\n",
        "        cls_token = self.class_token.view(1, 1, -1).expand(b*f, -1, -1)\n",
        "        x = torch.cat([cls_token, x], dim=1)\n",
        "        P = None\n",
        "        if return_ad_param:\n",
        "            # attn_output: [batch*frame, token/frame + class token, num_head, (dim/token) / num_head]\n",
        "            # x: [batch*frame, token/frame + class_token, dim/token]\n",
        "            x, attn_output = self.first_encoder(x, return_attn_output=True)\n",
        "            # -> [batch*frame, num_head, token/frame, (dim/token) / num_head]\n",
        "            attn_output = attn_output.permute(0, 2, 1, 3)[:, :, 1:, :]\n",
        "            # xi -> [batch*frame, token/frame, num_head, (dim/token) / num_head] -> [batch*frame, num_head, token/frame, (dim/token) / num_head]\n",
        "            train_in = train_in.reshape(-1, t, self.num_heads, d // self.num_heads).permute(0, 2, 1, 3)\n",
        "            P = attn_output * train_in\n",
        "            # [batch*frame, num_head, token/frame, (dim/token) / num_head] -> [batch*frame, num_head]\n",
        "            P = P.sum(dim=(2, 3))\n",
        "            # -> [batch, frame, num_head] -> [batch, num_head, frame]\n",
        "            P = P.reshape(b, f, -1).permute(0, 2, 1)\n",
        "        else:\n",
        "            x = self.first_encoder(x)\n",
        "\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x)\n",
        "\n",
        "        # Get only cls_token\n",
        "        # [batch * frame, 1, dim/token]\n",
        "        x = x[:, 0, :]\n",
        "        # [batch, frame, dim/token]\n",
        "        x = x.reshape(b, f, -1)\n",
        "        # [batch, dim/token]: Temporal Avg. Pooling\n",
        "        x = x.mean(dim=1)\n",
        "        embed = x\n",
        "        x = self.mlp_head(x)\n",
        "        res = [x]\n",
        "        if return_ad_param:\n",
        "            res.append(P)\n",
        "        if return_embed:\n",
        "            res.append(embed)\n",
        "        return tuple(res) if len(res) > 1 else res[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OflIU8asnbGT"
      },
      "outputs": [],
      "source": [
        "class ADLoss(nn.Module):\n",
        "    def __init__(self, num_cls=2, num_heads=12, max_len=32, delta_within=(0.01, -2.0), delta_between=0.5, eta=0.05):\n",
        "        super().__init__()\n",
        "        # C shape: [num_classes, num_heads, max_len]\n",
        "        # 논문 식(3)에 따라 센터를 각 클래스별로 유지해야 함\n",
        "        C = torch.zeros(num_cls, num_heads, max_len)\n",
        "        self.register_buffer('C', C)\n",
        "\n",
        "        self.num_cls = num_cls\n",
        "        self.num_heads = num_heads\n",
        "        self.delta_within = torch.tensor(delta_within) # [0.01, -2.0] (True, Fake)\n",
        "        self.delta_between = delta_between # 0.5\n",
        "        self.eta = eta\n",
        "\n",
        "    def forward(self, P, labels, log_detail=False):\n",
        "        \"\"\"\n",
        "        P: [batch, num_heads, max_len]\n",
        "        labels: [batch] (Class indices)\n",
        "        \"\"\"\n",
        "        device = P.device\n",
        "        # P: [B, H, F] -> [B, H*F]로 정규화하는 게 아니라,\n",
        "        # 각 헤드(H)별로 정규화해야 논문의 '헤드별 센터' 개념에 맞습니다.\n",
        "        P_norm = F.normalize(P, p=2, dim=2) # 각 헤드의 특징 벡터(F)를 정규화\n",
        "\n",
        "        # 1. 센터 업데이트 (현재 로직 유지하되 헤드별로 정규화 상태 유지)\n",
        "        if self.training:\n",
        "            for c in range(self.num_cls):\n",
        "                mask = (labels == c)\n",
        "                if mask.any():\n",
        "                    batch_class_mean = P_norm[mask].mean(dim=0) # [H, F]\n",
        "                    with torch.no_grad():\n",
        "                        self.C[c] = (1 - self.eta) * self.C[c] + self.eta * batch_class_mean.detach()\n",
        "\n",
        "        # 센터 정규화 (거리 계산 전 필수)\n",
        "        C_norm = F.normalize(self.C, p=2, dim=2) # [num_cls, H, F]\n",
        "\n",
        "        # --- 2. Within-class Loss (식 4) ---\n",
        "        # 각 샘플과 자기 클래스 센터 사이의 거리\n",
        "        # P: [B, H, F], self.C[labels]: [B, H, F]\n",
        "        diff_within = P_norm - C_norm[labels]\n",
        "        # L2 Norm 계산 (헤드와 프레임 차원에 대해)\n",
        "        dist_within = torch.norm(diff_within, p=2, dim=(1, 2))\n",
        "\n",
        "        # 각 샘플별 delta 적용\n",
        "        # loss_within = torch.relu(dist_within - self.delta_within[labels]).mean()\n",
        "\n",
        "        # 샘플 수와 상관없이 일정한 스케일 유지\n",
        "        loss_sum = 0.0\n",
        "        for c in range(self.num_cls):\n",
        "            mask = (labels == c)\n",
        "            if mask.any():\n",
        "                # 해당 클래스 샘플들만의 평균을 구함\n",
        "                class_loss = torch.relu(dist_within[mask] - self.delta_within[c]).mean()\n",
        "                loss_sum += class_loss\n",
        "        loss_within = loss_sum / self.num_cls # 클래스당 기여도를 1/N로 고정\n",
        "\n",
        "\n",
        "        # 3. Between-class Loss -> 사실상 \"Between-Head Diversity Loss\"\n",
        "        # 논문 식 (5)의 (k, l) in (nh, nh)를 구현\n",
        "        loss_between = 0.0\n",
        "        for c in range(self.num_cls):\n",
        "            # 한 클래스의 센터 내에 있는 12개 헤드 간의 거리를 계산\n",
        "            class_centers = C_norm[c] # [H, F]\n",
        "\n",
        "            # 헤드 간 Pairwise 거리: [H, H]\n",
        "            dist_matrix = torch.cdist(class_centers, class_centers, p=2)\n",
        "\n",
        "            # k != l 인 상삼각 행렬 마스크\n",
        "            mask = torch.triu(torch.ones(self.num_heads, self.num_heads, device=device), diagonal=1).bool()\n",
        "            different_heads_dist = dist_matrix[mask]\n",
        "\n",
        "            # 헤드들이 최소 delta_between만큼은 떨어져 있도록 함\n",
        "            loss_between += torch.relu(self.delta_between - different_heads_dist).mean()\n",
        "\n",
        "        loss_between /= self.num_cls # 클래스별 평균\n",
        "\n",
        "        if log_detail:\n",
        "            return loss_within + loss_between, loss_within, loss_between\n",
        "\n",
        "        return loss_within + loss_between"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "w_3YGmU93VT8"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.classification import Accuracy, AveragePrecision, Precision, Recall\n",
        "from torchmetrics import MetricCollection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mwpa-9_OuUpJ"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Literal\n",
        "from torchmetrics import ConfusionMatrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class LitUNITEClassifier(L.LightningModule):\n",
        "    def __init__(\n",
        "            self, num_cls=2, num_heads=12, max_len=32, dropout=0.1,\n",
        "            encoder_model=\"google/siglip2-base-patch16-384\", use_bfloat=True, cpu_preprocess=True,\n",
        "            delta_within=(0.01, -2.0), delta_between=0.5, eta=0.05,\n",
        "            lambda_1=0.5, lambda_2=0.5, lr=1e-4, decay_steps=1000,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model = UNITE(\n",
        "            num_cls=num_cls,\n",
        "            num_heads=num_heads,\n",
        "            max_len=max_len,\n",
        "            dropout=dropout,\n",
        "            encoder_model=encoder_model,\n",
        "            use_bfloat=use_bfloat,\n",
        "            cpu_preprocess=cpu_preprocess\n",
        "        )\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "        self.ad_loss = ADLoss(\n",
        "            num_cls=num_cls,\n",
        "            num_heads=num_heads,\n",
        "            max_len=max_len,\n",
        "            delta_within=delta_within,\n",
        "            delta_between=delta_between,\n",
        "            eta=eta,\n",
        "        )\n",
        "        self.lambda_1 = lambda_1\n",
        "        self.lambda_2 = lambda_2\n",
        "\n",
        "        self.lr = lr\n",
        "        self.decay_steps = decay_steps # Set this in respect to batch size; original batch size was 32\n",
        "\n",
        "        MetricType = TypedDict('MetricType', {\n",
        "            \"task\": Literal['multiclass'] | Literal['binary'],\n",
        "            \"num_classes\": int,\n",
        "            \"average\": Literal['macro'],\n",
        "        })\n",
        "\n",
        "        metric_param: MetricType = {\"task\": \"multiclass\", \"num_classes\": num_cls, \"average\": \"macro\"}\n",
        "\n",
        "        metrics = MetricCollection([\n",
        "            Accuracy(**metric_param), AveragePrecision(**metric_param), Precision(**metric_param), Recall(**metric_param)\n",
        "        ])\n",
        "\n",
        "        self.val_metrics = metrics.clone(prefix=\"val/\")\n",
        "        self.test_metrics = metrics.clone(prefix=\"test/\")\n",
        "\n",
        "        self.confmat = ConfusionMatrix(task='multiclass', num_classes=num_cls)\n",
        "        self.num_cls = num_cls\n",
        "\n",
        "        self.val_embeds = []\n",
        "        self.val_labels = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def on_save_checkpoint(self, checkpoint):\n",
        "        \"\"\"체크포인트 저장 시 Frozen 파라미터(Backbone)를 제외합니다.\"\"\"\n",
        "        state_dict = checkpoint['state_dict']\n",
        "\n",
        "        # 저장하지 않을 키 필터링 (vis_encoder 관련 키들 제거)\n",
        "        # 키 이름은 모델 구조에 따라 'model.vis_encoder.'로 시작합니다.\n",
        "        keys_to_remove = [k for k in state_dict.keys() if \"model.vis_encoder\" in k]\n",
        "\n",
        "        for k in keys_to_remove:\n",
        "            del state_dict[k]\n",
        "\n",
        "    def on_load_checkpoint(self, checkpoint):\n",
        "        \"\"\"로드 시 체크포인트에 없는 백본 가중치를 현재 모델에서 복사해서 채워줌\"\"\"\n",
        "        state_dict = checkpoint['state_dict']\n",
        "        model_state_dict = self.state_dict()\n",
        "\n",
        "        # 현재 모델(self.model.vis_encoder)은 이미 __init__에서\n",
        "        # from_pretrained로 로드된 상태입니다.\n",
        "        # 체크포인트에 없는 키(백본 가중치)들을 모델의 현재 가중치로 채워줍니다.\n",
        "        for key in model_state_dict:\n",
        "            if key not in state_dict:\n",
        "                state_dict[key] = model_state_dict[key]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logit, P = self.model(x, return_ad_param=True)\n",
        "        loss_ad, within, between = self.ad_loss(P, y, log_detail=True)\n",
        "        loss_ce = self.ce_loss(logit, y)\n",
        "        loss = loss_ce * self.lambda_1 + loss_ad * self.lambda_2\n",
        "\n",
        "\n",
        "        self.log_dict({\n",
        "            \"train/loss_ad\": loss_ad,\n",
        "            \"train/loss_ad/loss_within\": within,\n",
        "            \"train/loss_ad/loss_between\": between,\n",
        "            \"train/loss_ce\": loss_ce,\n",
        "            \"train/loss\": loss,\n",
        "        }, logger=True)\n",
        "\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logit, P = self.model(x, return_ad_param=True)\n",
        "        loss_ad = self.ad_loss(P, y)\n",
        "        loss_ce = self.ce_loss(logit, y)\n",
        "        loss = loss_ce * self.lambda_1 + loss_ad * self.lambda_2\n",
        "        self.log(\"val/loss_ad\", loss_ad, logger=True)\n",
        "        self.log(\"val/loss_ce\", loss_ce, logger=True)\n",
        "        self.log(\"val/loss\", loss, prog_bar=True, logger=True)\n",
        "\n",
        "        self.val_metrics.update(logit, y)\n",
        "        self.log_dict(self.val_metrics, logger=True)\n",
        "\n",
        "\n",
        "    def on_test_epoch_start(self):\n",
        "        self.test_preds = []\n",
        "        self.test_labels = []\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logit = self.model(x)\n",
        "        preds = torch.argmax(logit, dim=1)\n",
        "\n",
        "        self.test_preds.append(preds.detach())\n",
        "        self.test_labels.append(y.detach())\n",
        "\n",
        "        self.test_metrics.update(logit, y)\n",
        "        self.log_dict(self.test_metrics, logger=True)\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        all_preds = torch.cat(self.test_preds)\n",
        "        all_labels = torch.cat(self.test_labels)\n",
        "        conf_matrix = self.confmat(all_preds, all_labels)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        fig = plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(\n",
        "            conf_matrix.cpu().numpy(),\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap='Blues',\n",
        "            xticklabels=[f'Class {i}' for i in range(self.num_cls)],\n",
        "            yticklabels=[f'Class {i}' for i in range(self.num_cls)]\n",
        "        )\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix')\n",
        "        self.logger.experiment.log({\"Confusion Matrix\": wandb.Image(fig)})\n",
        "        plt.close(fig)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.AdamW(self.model.parameters(), lr=self.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optim, self.decay_steps, gamma=0.5)\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": optim,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"interval\": \"step\",\n",
        "            },\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HTUa5d_5Vd2b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import cv2\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from typing import Sequence\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchcodec.decoders import VideoDecoder\n",
        "import transformers\n",
        "\n",
        "class CelebDFBaseDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Celeb-DF 데이터셋의 공통 기능을 담은 부모 클래스\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            paths: Sequence[Path | str],\n",
        "            length=32, size=(384, 384),\n",
        "            transform=None,\n",
        "            device='cpu',\n",
        "            encoder_model=\"google/siglip2-base-patch16-224\",\n",
        "            cpu_preprocess=False,\n",
        "        ):\n",
        "        self.length = length\n",
        "        self.size = size\n",
        "        self.transform = transform\n",
        "        self.device = device\n",
        "        self.samples = []\n",
        "\n",
        "        print(f\"Processing {len(paths)} paths...\")\n",
        "        self._prepare_samples(paths)\n",
        "        print(f\"Loaded {len(self.samples)} samples from {len(paths)} files/directories.\")\n",
        "\n",
        "        self.preprocessor = None\n",
        "        self.cpu_preprocess = cpu_preprocess\n",
        "        if cpu_preprocess:\n",
        "            self.preprocessor = transformers.AutoProcessor.from_pretrained(\n",
        "                encoder_model,\n",
        "                use_fast=True\n",
        "            )\n",
        "\n",
        "    def _get_label(self, path: str) -> int | None:\n",
        "        \"\"\"폴더명 기반 레이블 결정\"\"\"\n",
        "        rel_path = path.replace(\"\\\\\", \"/\")\n",
        "        if \"YouTube-real\" in rel_path or \"Celeb-real\" in rel_path:\n",
        "            return 0\n",
        "        elif \"Celeb-synthesis\" in rel_path:\n",
        "            return 1\n",
        "        return None\n",
        "\n",
        "    def _prepare_samples(self, paths: Sequence[Path | str]):\n",
        "        \"\"\"상속받는 클래스에서 각자의 방식으로 samples 리스트를 채움\"\"\"\n",
        "        for path in paths:\n",
        "            path_str = str(path)\n",
        "            label = self._get_label(path_str)\n",
        "            if label is None:\n",
        "                continue\n",
        "\n",
        "            frame_cnt = self._get_frame_count(path_str)\n",
        "            if frame_cnt <= 0:\n",
        "                continue\n",
        "\n",
        "            num_chunks = self._calculate_num_chunks(frame_cnt)\n",
        "            for i in range(num_chunks):\n",
        "                self.samples.append({\n",
        "                    \"path\": path_str,\n",
        "                    \"chunk_idx\": i,\n",
        "                    \"label\": label,\n",
        "                    \"total_frames\": frame_cnt\n",
        "                })\n",
        "\n",
        "    def _get_frame_count(self, path: str) -> int:\n",
        "        \"\"\"자식 클래스에서 구현: 전체 프레임 수 반환\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _calculate_num_chunks(self, frame_cnt: int) -> int:\n",
        "        \"\"\"자식 클래스에서 구현: 프레임 수에 따른 청크 개수 계산\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_label_counter(self) -> Counter:\n",
        "        return Counter([x['label'] for x in self.samples])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"자식 클래스에서 구현: 실제 데이터 로드\"\"\"\n",
        "        raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mCig1aG-MBvI"
      },
      "outputs": [],
      "source": [
        "class CelebDFVideoDataset(CelebDFBaseDataset):\n",
        "    \"\"\"\n",
        "    비디오 파일(.mp4 등)에서 직접 프레임을 추출하는 데이터셋\n",
        "    \"\"\"\n",
        "    def _get_frame_count(self, path: str) -> int:\n",
        "        cap = cv2.VideoCapture(path)\n",
        "        cnt = 0\n",
        "        if cap.isOpened():\n",
        "            cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            cap.release()\n",
        "        return cnt\n",
        "\n",
        "    def _calculate_num_chunks(self, frame_cnt: int) -> int:\n",
        "        # Stride=2를 고려한 유효 프레임 기반 계산\n",
        "        effective_frames = math.ceil(frame_cnt / 2)\n",
        "        return math.ceil(effective_frames / self.length)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        meta = self.samples[idx]\n",
        "        video_path, chunk_idx, label = meta[\"path\"], meta[\"chunk_idx\"], meta[\"label\"]\n",
        "\n",
        "        try:\n",
        "            decoder = VideoDecoder(video_path, device=self.device)\n",
        "            total_frames = decoder.metadata.num_frames or 100000\n",
        "\n",
        "            # Stride 2 적용하여 인덱스 계산\n",
        "            start_frame = chunk_idx * self.length * 2\n",
        "            indices = [min(start_frame + (i * 2), total_frames - 1) for i in range(self.length)]\n",
        "\n",
        "            frames_batch = decoder.get_frames_at(indices=indices)\n",
        "            frames_tensor = frames_batch.data  # (N, C, H, W)\n",
        "\n",
        "            if self.cpu_preprocess:\n",
        "                assert self.preprocessor is not None\n",
        "                processed = self.preprocessor(images=frames_tensor, return_tensors=\"pt\")\n",
        "                frames_tensor = processed.pixel_values  # Shape: (N, C, H, W)\n",
        "\n",
        "            # (N, C, H, W) -> (C, N, H, W)\n",
        "            frames_tensor = frames_tensor.permute(1, 0, 2, 3)\n",
        "\n",
        "            if self.transform:\n",
        "                # Video transform이 필요한 경우 여기서 처리 (Batch 단위 지원 필요)\n",
        "                pass\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {video_path}: {e}\")\n",
        "            if self.cpu_preprocess:\n",
        "                frames_tensor = torch.zeros((3, self.length, self.size[1], self.size[0]), dtype=torch.float32)\n",
        "            else:\n",
        "                frames_tensor = torch.zeros((3, self.length, self.size[1], self.size[0]), dtype=torch.uint8)\n",
        "\n",
        "\n",
        "\n",
        "        return frames_tensor.contiguous(), torch.tensor(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0lkjeBIn1ieK"
      },
      "outputs": [],
      "source": [
        "class CelebDFImageDataset(CelebDFBaseDataset):\n",
        "    \"\"\"\n",
        "    이미지 파일이 저장된 폴더에서 프레임을 읽어오는 데이터셋\n",
        "    \"\"\"\n",
        "    def _get_frame_count(self, path: str) -> int:\n",
        "        try:\n",
        "            return len([f for f in os.listdir(path) if f.endswith(('.jpg', '.png'))])\n",
        "        except Exception:\n",
        "            return 0\n",
        "\n",
        "    def _calculate_num_chunks(self, frame_cnt: int) -> int:\n",
        "        # 이미 전처리가 완료된 상태이므로 stride 없이 계산\n",
        "        return math.ceil(frame_cnt / self.length)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        meta = self.samples[idx]\n",
        "        folder_path, chunk_idx, label, total_frames = meta[\"path\"], meta[\"chunk_idx\"], meta[\"label\"], meta[\"total_frames\"]\n",
        "\n",
        "        frames_list = []\n",
        "        start_frame_idx = chunk_idx * self.length\n",
        "\n",
        "        for i in range(self.length):\n",
        "            current_idx = min(start_frame_idx + i, total_frames - 1)\n",
        "            file_name = f\"frame_{current_idx + 1:06d}.jpg\"\n",
        "            img_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "            try:\n",
        "                img_tensor = read_image(img_path, mode=ImageReadMode.RGB)\n",
        "                if self.transform:\n",
        "                    img_tensor = self.transform(img_tensor)\n",
        "                frames_list.append(img_tensor)\n",
        "            except Exception:\n",
        "                frames_list.append(torch.zeros((3, self.size[1], self.size[0]), dtype=torch.uint8))\n",
        "\n",
        "        if frames_list:\n",
        "            frames_tensor = torch.stack(frames_list, dim=0) # (N, C, H, W)\n",
        "            if self.cpu_preprocess:\n",
        "                assert self.preprocessor is not None\n",
        "                processed = self.preprocessor(images=frames_tensor, return_tensors=\"pt\")\n",
        "                frames_tensor = processed.pixel_values  # Shape: (N, C, H, W)\n",
        "            frames_tensor = frames_tensor.permute(1, 0, 2, 3) # (C, N, H, W)\n",
        "        else:\n",
        "            if self.cpu_preprocess:\n",
        "                frames_tensor = torch.zeros((3, self.length, self.size[1], self.size[0]), dtype=torch.float32)\n",
        "            else:\n",
        "                frames_tensor = torch.zeros((3, self.length, self.size[1], self.size[0]), dtype=torch.uint8)\n",
        "\n",
        "        return frames_tensor.contiguous(), torch.tensor(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D-Uafut510Lu"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm.notebook import tqdm\n",
        "from shutil import copy2\n",
        "import os\n",
        "\n",
        "def resize_single_video(item):\n",
        "    src_path, dst_path, size = item\n",
        "    # 폴더가 없으면 생성\n",
        "    dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # FFmpeg 명령어 구성\n",
        "    # -y: 기존 파일 덮어쓰기\n",
        "    # -i: 입력 파일\n",
        "    # -vf: 비디오 필터 (리사이즈)\n",
        "    # -c:v libx264: H.264 코덱 사용\n",
        "    # -crf 23: 일반적인 화질 설정 (낮을수록 고화질)\n",
        "    # -preset veryfast: 속도 우선 인코딩\n",
        "    # -an: 오디오 제거 (학습에 필요 없음, 용량 절감)\n",
        "    cmd = [\n",
        "        'ffmpeg', '-y',\n",
        "        '-hwaccel', 'cuda',             # 디코딩 가속 유지\n",
        "        '-i', str(src_path),\n",
        "        # 성공했던 코드의 필터 형식을 그대로 사용 (flags=lanczos 등)\n",
        "        '-vf', f\"scale={size[0]}:{size[1]}:flags=lanczos\",\n",
        "        '-c:v', 'libx264',              # NVENC 대신 검증된 libx264 사용\n",
        "        '-preset', 'fast',              # 속도 조절\n",
        "        '-crf', '23',                   # 화질 설정\n",
        "        '-pix_fmt', 'yuv420p',          # 재생 호환성을 위해 추가\n",
        "        '-an',                          # 오디오 제거\n",
        "        str(dst_path)\n",
        "    ]\n",
        "\n",
        "    # 실행 (로그는 숨김)\n",
        "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    # ... (cmd 설정 부분)\n",
        "\n",
        "\n",
        "def preprocess_celebdf(src_root, dst_root, size=(384, 384), max_workers=8):\n",
        "    src_root = Path(src_root)\n",
        "    dst_root = Path(dst_root)\n",
        "\n",
        "    if dst_root.exists():\n",
        "        print(f\"Target directory {dst_root} already exists. Skipping preprocessing.\")\n",
        "        return\n",
        "\n",
        "    # 모든 mp4 파일 찾기\n",
        "    video_files = list(src_root.glob(\"*/*.mp4\"))\n",
        "    tasks = []\n",
        "\n",
        "    for src_path in video_files:\n",
        "        rel_path = src_path.relative_to(src_root)\n",
        "        dst_path = dst_root / rel_path\n",
        "        if not dst_path.exists():\n",
        "            tasks.append((src_path, dst_path, size))\n",
        "\n",
        "    print(f\"Starting preprocessing: {len(tasks)} videos...\")\n",
        "\n",
        "    # 멀티프로세싱으로 병렬 처리\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "        list(tqdm(executor.map(resize_single_video, tasks, chunksize=4), total=len(tasks)))\n",
        "    copy2(src_root / \"List_of_testing_videos.txt\", dst_root / \"List_of_testing_videos.txt\")\n",
        "\n",
        "    print(\"Preprocessing completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_a_Hd4cVNV2H"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm.notebook import tqdm\n",
        "from shutil import copy2\n",
        "import os\n",
        "\n",
        "def extract_frames_single_video(item):\n",
        "    src_path, dst_dir, size = item\n",
        "\n",
        "    if dst_dir.exists() and any(dst_dir.iterdir()):\n",
        "        return\n",
        "\n",
        "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    output_pattern = str(dst_dir / \"frame_%06d.jpg\")\n",
        "\n",
        "    # FFmpeg 명령어 변경\n",
        "    # -vf \"select='not(mod(n\\,2))',scale=...\":\n",
        "    #   1. select: 짝수 프레임(0, 2, 4...)만 선택\n",
        "    #   2. scale: 리사이즈\n",
        "    # -vsync vfr: 선택된 프레임만 출력 (타임스탬프 유지를 위해 빈 프레임 생성 방지)\n",
        "    cmd = [\n",
        "        'ffmpeg', '-y',\n",
        "        '-hwaccel', 'cuda',\n",
        "        '-i', str(src_path),\n",
        "        '-vf', rf\"select='not(mod(n\\,2))',scale={size[0]}:{size[1]}:flags=lanczos\",\n",
        "        '-vsync', 'vfr', # Variable Frame Rate: 선택된 프레임만 씀\n",
        "        '-q:v', '2',\n",
        "        output_pattern,\n",
        "        '-threads', '1',\n",
        "        '-hide_banner', '-loglevel', 'error'\n",
        "    ]\n",
        "\n",
        "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "def preprocess_celebdf_frames(src_root, dst_root, size=(384, 384), max_workers=8):\n",
        "    src_root = Path(src_root)\n",
        "    dst_root = Path(dst_root)\n",
        "\n",
        "    video_files = list(src_root.glob(\"*/*.mp4\"))\n",
        "    tasks = []\n",
        "\n",
        "    print(f\"Scanning files...\")\n",
        "    for src_path in video_files:\n",
        "        rel_path = src_path.relative_to(src_root)\n",
        "        dst_dir = dst_root / rel_path.with_suffix('')\n",
        "\n",
        "        if not dst_dir.exists() or not any(dst_dir.iterdir()):\n",
        "            tasks.append((src_path, dst_dir, size))\n",
        "\n",
        "    print(f\"Starting frame extraction (Even frames only): {len(tasks)} videos...\")\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "        list(tqdm(executor.map(extract_frames_single_video, tasks, chunksize=1), total=len(tasks)))\n",
        "\n",
        "    txt_src = src_root / \"List_of_testing_videos.txt\"\n",
        "    if txt_src.exists():\n",
        "        copy2(txt_src, dst_root / \"List_of_testing_videos.txt\")\n",
        "\n",
        "    print(\"Preprocessing completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ca-lGJcDUxBV"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "\n",
        "class CelebDFDataModule(L.LightningDataModule):\n",
        "    def __init__(\n",
        "            self, length=32, batch_size=32, num_workers=8, size=(384, 384),\n",
        "            path=\"/content/preprocessed\", from_img=True, val_split_ratio=0.1,\n",
        "            device='cpu', prefetch_factor=1, pin_memory=True, persistent_worker=True,\n",
        "            encoder_model=\"google/siglip2-base-patch16-384\", cpu_preprocess=False):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.length = length\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.path = Path(path)\n",
        "        self.dataset_cls: type[CelebDFBaseDataset] = CelebDFImageDataset\n",
        "        self.dataset_preprocess_method = preprocess_celebdf_frames\n",
        "        self.from_img = from_img\n",
        "        if from_img == False:\n",
        "            self.dataset_cls = CelebDFVideoDataset\n",
        "            self.dataset_preprocess_method = preprocess_celebdf\n",
        "        self.prefetch_factor = prefetch_factor\n",
        "        self.pin_memory = pin_memory\n",
        "        self.val_split_ratio = val_split_ratio\n",
        "        self.size = size\n",
        "        self.persistent_worker = persistent_worker\n",
        "        self.device = device\n",
        "        self.encoder_model = encoder_model\n",
        "        self.cpu_preprocess = cpu_preprocess\n",
        "\n",
        "    def prepare_data(self):\n",
        "        path = kagglehub.dataset_download(\"reubensuju/celeb-df-v2\")\n",
        "        self.dataset_preprocess_method(path, self.path, size=self.size)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            # 1. 모든 비디오 폴더 경로 가져오기\n",
        "            # 전처리된 이미지 폴더 구조: root/Celeb-real/id0_0000 ...\n",
        "            # glob을 이용해 실제 폴더들을 다 찾습니다.\n",
        "            all_folders = []\n",
        "            if self.from_img:\n",
        "                all_folders = [Path(x) for x in self.path.glob(\"*/*\") if os.path.isdir(x)]\n",
        "            else:\n",
        "                all_folders = [Path(x) for x in self.path.glob(\"*/*.mp4\")]\n",
        "\n",
        "            # 2. Test Set 목록 로드 및 제외\n",
        "            txt_path = self.path / \"List_of_testing_videos.txt\"\n",
        "            test_df = pd.read_csv(txt_path, sep=\" \", header=None, names=[\"label\", \"path\"])\n",
        "            test_paths_set = set()\n",
        "            if self.from_img:\n",
        "                # 확장자를 떼고 비교해야 함 (이미지 폴더명은 확장자가 없으므로)\n",
        "                test_paths_set = set(\n",
        "                    test_df[\"path\"].apply(lambda x: str(self.path / Path(x).with_suffix('')).replace(\"\\\\\", \"/\")).values\n",
        "                )\n",
        "            else:\n",
        "                test_paths_set = set(test_df[\"path\"].apply(lambda x: str(self.path / x)).replace(\"\\\\\", \"/\").values)\n",
        "\n",
        "            train_val_candidates = []\n",
        "            for folder in all_folders:\n",
        "                # 경로 정규화\n",
        "                folder_str = str(folder).replace(\"\\\\\", \"/\")\n",
        "                # 테스트 셋에 포함되지 않은 것만 Train/Val 후보로 등록\n",
        "                if folder_str not in test_paths_set:\n",
        "                     train_val_candidates.append(folder_str)\n",
        "\n",
        "            # 3. 비디오 단위로 Train / Val 분리 (가장 중요!)\n",
        "            # 여기서 쪼개야 비디오 하나가 통째로 Train이나 Val 한쪽으로만 갑니다.\n",
        "            train_videos, val_videos = train_test_split(\n",
        "                train_val_candidates,\n",
        "                test_size=self.val_split_ratio,\n",
        "                random_state=42,\n",
        "                shuffle=True\n",
        "            )\n",
        "\n",
        "            print(f\"Total Train/Val Videos: {len(train_val_candidates)}\")\n",
        "            print(f\"Split result -> Train Videos: {len(train_videos)}, Val Videos: {len(val_videos)}\")\n",
        "\n",
        "            # 4. 데이터셋 인스턴스 생성 (video_paths 주입)\n",
        "            self.celebdf_train = self.dataset_cls(\n",
        "                paths=train_videos,\n",
        "                length=self.length,\n",
        "                size=self.size,\n",
        "                device=self.device,\n",
        "                encoder_model=self.encoder_model,\n",
        "                cpu_preprocess=self.cpu_preprocess,\n",
        "            )\n",
        "\n",
        "            self.celebdf_val = self.dataset_cls(\n",
        "                paths=val_videos,\n",
        "                length=self.length,\n",
        "                size=self.size,\n",
        "                device=self.device,\n",
        "                encoder_model=self.encoder_model,\n",
        "                cpu_preprocess=self.cpu_preprocess,\n",
        "            )\n",
        "\n",
        "        if stage == \"test\" or stage is None:\n",
        "            # 테스트 셋은 기존 로직(txt 파일 기반)을 유지하거나,\n",
        "            # 위에서 test_paths_set을 리스트로 변환해 넘겨줘도 됩니다.\n",
        "            # 여기서는 편의상 기존 클래스가 is_test=True일 때 txt 파일을 읽는 로직을 그대로 쓴다고 가정하거나\n",
        "            # 혹은 위와 똑같이 리스트를 만들어서 넘겨줍니다.\n",
        "\n",
        "            # Test 리스트 생성 로직\n",
        "            txt_path = self.path / \"List_of_testing_videos.txt\"\n",
        "            test_df = pd.read_csv(txt_path, sep=\" \", header=None, names=[\"label\", \"path\"])\n",
        "            test_videos = []\n",
        "            if self.from_img:\n",
        "                test_videos = [\n",
        "                    str(self.path / Path(x).with_suffix('')).replace(\"\\\\\", \"/\")\n",
        "                    for x in test_df[\"path\"].values\n",
        "                ]\n",
        "            else:\n",
        "                test_videos = [str(self.path / Path(x)) for x in test_df[\"path\"].values]\n",
        "            # 실제 존재하는 폴더만 필터링\n",
        "            test_videos = [v for v in test_videos if os.path.exists(v)]\n",
        "\n",
        "            self.celebdf_test = self.dataset_cls(\n",
        "                paths=test_videos,\n",
        "                length=self.length,\n",
        "                size=self.size,\n",
        "                device=self.device,\n",
        "                encoder_model=self.encoder_model,\n",
        "                cpu_preprocess=self.cpu_preprocess,\n",
        "            )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # 2. 현재 훈련 셋(Subset) 내의 클래스별 개수 계산\n",
        "        label_counts = self.celebdf_train.get_label_counter()\n",
        "\n",
        "        # 3. 클래스별 가중치 계산 (1 / 개수)\n",
        "        # 예: Real이 100개, Fake가 1000개면 가중치는 Real: 0.01, Fake: 0.001\n",
        "        class_weights = {label: 1.0 / count for label, count in label_counts.items()}\n",
        "\n",
        "        # 4. 각 샘플에 대한 가중치 리스트 생성 (Subset의 순서와 일치해야 함)\n",
        "        sample_weights = [class_weights[sample['label']]\n",
        "                          for sample in self.celebdf_train.samples]\n",
        "\n",
        "        # 5. 샘플러 생성\n",
        "        # num_samples는 보통 학습 데이터 전체 길이로 설정합니다.\n",
        "        # replacement=True여야 불균형 데이터에서 적은 쪽을 중복해서 뽑아 균형을 맞춥니다.\n",
        "        sampler = WeightedRandomSampler(\n",
        "            weights=sample_weights,\n",
        "            num_samples=len(sample_weights),\n",
        "            replacement=True\n",
        "        )\n",
        "\n",
        "        return DataLoader(\n",
        "            self.celebdf_train,\n",
        "            num_workers=self.num_workers,\n",
        "            batch_size=self.batch_size,\n",
        "            pin_memory=self.pin_memory,\n",
        "            persistent_workers=self.persistent_worker,\n",
        "            prefetch_factor=self.prefetch_factor,\n",
        "            sampler=sampler,\n",
        "        )\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.celebdf_val,\n",
        "            num_workers=self.num_workers,\n",
        "            batch_size=self.batch_size,\n",
        "            pin_memory=self.pin_memory,\n",
        "            persistent_workers=self.persistent_worker,\n",
        "        )\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.celebdf_test,\n",
        "            num_workers=self.num_workers,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb8kC4NdXpMX",
        "outputId": "28b8132b-c5fb-4cc5-a03f-51a3073d7602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhnam0502\u001b[0m (\u001b[33mdhnam0502-likelion\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "wandb_key = userdata.get('wandb_api')\n",
        "wandb.login(key=wandb_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TvJmnC34YCFF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61,
          "referenced_widgets": [
            "e6f58758710b410cbcc0321e8a27734d",
            "1d0978dada8a4d40abfb3ad342ace9a5",
            "eddeb91ed04f43b085bc110a8770a1b3",
            "0ad43919760a40fdb7b6ceb6cfa8bc11",
            "4272e77b8db14078b9a3cfe524a11c83",
            "6065328ba8664b47bd47647b9b3a26a9",
            "613bff1ec61d40f9a7eb164e060c718f",
            "23d2239a53234b528019642cafbe313e",
            "37768f5ed1974541affb5eab0962a0ff",
            "ca96a9519bf04702a7baebcbd8d3530f",
            "3ec2aae1cb12483bae5cb7a02a8343ea"
          ]
        },
        "outputId": "ad452f67-7633-4b96-d1ef-5f47cd1ac1d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/408 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6f58758710b410cbcc0321e8a27734d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "BATCH_SIZE = 12\n",
        "DECAY_STEPS = (1000 * 32) // BATCH_SIZE\n",
        "LENGTH = 32\n",
        "SIZE = (224, 224)\n",
        "import os\n",
        "\n",
        "datamodule = CelebDFDataModule(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=8,\n",
        "    prefetch_factor=2,\n",
        "    device='cpu',\n",
        "    # prefetch_factor=None,\n",
        "    pin_memory=True,\n",
        "    path=\"/dev/shm/preprocessed\",\n",
        "    from_img=False,\n",
        "    length=LENGTH,\n",
        "    size=SIZE,\n",
        "    persistent_worker=True,\n",
        "    # persistent_worker=False,\n",
        "    encoder_model=\"google/siglip2-base-patch16-224\",\n",
        "    cpu_preprocess=True,\n",
        "\n",
        ")\n",
        "lit_classifier = LitUNITEClassifier(\n",
        "    decay_steps=DECAY_STEPS,\n",
        "    delta_within=(0.01, -2),\n",
        "    delta_between=0.5,\n",
        "    lambda_1=0.5,\n",
        "    lambda_2=0.5,\n",
        "    encoder_model=\"google/siglip2-base-patch16-224\",\n",
        "    use_bfloat=True,\n",
        "    max_len=LENGTH,\n",
        "    cpu_preprocess=True,\n",
        ")\n",
        "# lit_classifier = torch.compile(lit_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H637pv3OVro",
        "outputId": "7f914d98-462d-4e5b-dab3-c69327b21989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'celeb-df-v2' dataset.\n",
            "Target directory /dev/shm/preprocessed already exists. Skipping preprocessing.\n"
          ]
        }
      ],
      "source": [
        "datamodule.prepare_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHRx1khcaAoV",
        "outputId": "626187c5-aef9-409f-8513-3d9e03af6232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n"
          ]
        }
      ],
      "source": [
        "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
        "from lightning.pytorch.callbacks.lr_monitor import LearningRateMonitor\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from lightning.pytorch.callbacks import TQDMProgressBar\n",
        "from lightning.pytorch.profilers import AdvancedProfiler\n",
        "\n",
        "profiler = AdvancedProfiler(\".\", \"profile\")\n",
        "\n",
        "\n",
        "wandb_logger = WandbLogger(\n",
        "    project=\"UNITE_deepfake_classification\",\n",
        "    name=\"baseline_test_fixed2\",\n",
        "    log_model=False,\n",
        ")\n",
        "\n",
        "# ckpt = ModelCheckpoint(monitor=\"val/acc\", mode=\"max\", save_last=True)\n",
        "ckpt_drive = ModelCheckpoint(dirpath=\"/content/drive/MyDrive/bootcamp_proj/final/fixed/\", monitor=\"val/MulticlassAccuracy\", mode=\"max\", save_last=True)\n",
        "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
        "\n",
        "trainer =  L.Trainer(\n",
        "    max_epochs=10,\n",
        "    # max_steps=100,\n",
        "    # profiler=profiler,\n",
        "    logger=wandb_logger,\n",
        "    callbacks=[ckpt_drive, lr_monitor],\n",
        "    precision='bf16-mixed',\n",
        "    log_every_n_steps=50,\n",
        "    # precision=16,\n",
        "    # fast_dev_run=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rkwkGvjlbUN6"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnPg2QCWc-Ln",
        "outputId": "ca920041-4d26-4852-8a60-2ca8be99175e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  _C._set_float32_matmul_precision(precision)\n"
          ]
        }
      ],
      "source": [
        "torch.set_float32_matmul_precision('high')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "pNqNPyd7bQsH",
        "outputId": "8780b6c7-bb38-457e-c799-3236462ffb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'celeb-df-v2' dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target directory /dev/shm/preprocessed already exists. Skipping preprocessing.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>wandb/run-20260203_071720-44fqh1uv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dhnam0502-likelion/UNITE_deepfake_classification/runs/44fqh1uv' target=\"_blank\">baseline_test_fixed2</a></strong> to <a href='https://wandb.ai/dhnam0502-likelion/UNITE_deepfake_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dhnam0502-likelion/UNITE_deepfake_classification' target=\"_blank\">https://wandb.ai/dhnam0502-likelion/UNITE_deepfake_classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dhnam0502-likelion/UNITE_deepfake_classification/runs/44fqh1uv' target=\"_blank\">https://wandb.ai/dhnam0502-likelion/UNITE_deepfake_classification/runs/44fqh1uv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Train/Val Videos: 6011\n",
            "Split result -> Train Videos: 5409, Val Videos: 602\n",
            "Processing 5409 paths...\n",
            "Loaded 34682 samples from 5409 files/directories.\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(lit_classifier, datamodule=datamodule)\n",
        "# trainer.fit(lit_classifier, datamodule=datamodule, ckpt_path='/content/UNITE_deepfake_classification/93i7lafx/checkpoints/last.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "th2TtdikB8uj"
      },
      "outputs": [],
      "source": [
        "# del lit_classifier\n",
        "# del trainer\n",
        "# del datamodule\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gTDntWy3dyIH",
        "outputId": "3d1e958a-f365-4018-dc61-5cc63fb5dcd5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/bootcamp_proj/final/v2/last-v1.ckpt'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.checkpoint_callback.last_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jsHsIls6GJyS",
        "outputId": "e1c9819b-ad1f-42ce-fe3a-5f5b6d0eb375"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/bootcamp_proj/final/v2/epoch=4-step=7890.ckpt'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.checkpoint_callback.best_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9nnHVLJAhwW"
      },
      "outputs": [],
      "source": [
        "lit_classifier = LitUNITEClassifier.load_from_checkpoint(trainer.checkpoint_callback.last_model_path, strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560,
          "referenced_widgets": [
            "9da13c1b7c404efa88ac3d2b40f4b91b",
            "d554a8c379854e47b930bc657aead223",
            "e66c0970e4f24848bf53e72a54a28fb9",
            "a274e9e768994b20b00bb9959611fc98",
            "ac1adc863f3e42dabf351cc4bb97c55b",
            "aed39ae258ba4dcfb14f17b28708312a",
            "31ee7ecaeeea4c7d8069813b043bcc0c",
            "7b8761761a0541e6b150d15b4de8e049",
            "b6eec428cb5242b4b7c143c128636e58",
            "fb475a9673c04d4d821b032f9c702c88",
            "e421121df89945d2a9cc4bc18bb92912",
            "c220861f5d0c4e3a88925ff63c0d6638",
            "24856f9a1aa1413090eca37245f47792"
          ]
        },
        "id": "Yn1giSd-2JLs",
        "outputId": "beb4e14d-bcbb-4b01-f448-1fc0003f1950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'celeb-df-v2' dataset.\n",
            "Scanning files...\n",
            "Starting frame extraction (Even frames only): 0 videos...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9da13c1b7c404efa88ac3d2b40f4b91b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing completed.\n",
            "Processing metadata for Test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 3359 samples from 6529 directories.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c220861f5d0c4e3a88925ff63c0d6638",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found\n",
              "in target, recall is undefined. Setting recall to one for all thresholds.\n",
              "  warnings.warn(*args, **kwargs)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found\n",
              "in target, recall is undefined. Setting recall to one for all thresholds.\n",
              "  warnings.warn(*args, **kwargs)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Average precision score \n",
              "for one or more classes was `nan`. Ignoring these classes in macro-average\n",
              "  warnings.warn(*args, **kwargs)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Average precision score \n",
              "for one or more classes was `nan`. Ignoring these classes in macro-average\n",
              "  warnings.warn(*args, **kwargs)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.861244797706604     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/ap          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9100767970085144     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9124864935874939     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.861244797706604     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.861244797706604    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m         test/ap         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9100767970085144    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test/precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9124864935874939    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m       test/recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.861244797706604    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test/acc': 0.861244797706604,\n",
              "  'test/ap': 0.9100767970085144,\n",
              "  'test/precision': 0.9124864935874939,\n",
              "  'test/recall': 0.861244797706604}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(model=lit_classifier, datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZcUlpmlcfSy",
        "outputId": "710936f2-016e-4ccb-9b1b-a636db88e533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -hwaccels | grep cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75LctAT8HiSk"
      },
      "outputs": [],
      "source": [
        "!cp /content/UNITE_deepfake_classification/93i7lafx/checkpoints/last.ckpt /content/drive/MyDrive/bootcamp_proj/final/v2/last.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "ddd628f54475406994046cd27030bc2c",
            "d713c474f1504c57a6f815cc965de362",
            "f65f95c6f49b4ce8a9aa96c566331e68",
            "d0b6ba3e0dfa4ead8b61984a24e79b85",
            "8a313f8222214631816864bedb6ba010",
            "9bea896a919b42dab93cd75f679a8a19",
            "b2de770d479f432ab52b74f3cb445fbe",
            "b5858ce3a17c41f18ca559cea532d34d",
            "5a8e27aa4d4a469fbaf6a7b0197685e2",
            "e9fc87297401453cb0d8854d3b66e540",
            "ae9150ba3b3f4389a6ce2a504bd3e269",
            "f40bd6bed8304a93b7b2760bc81c3047",
            "33cdd44a03a344ecb6ac265d8f58ecfe",
            "8ce5a029ec634b54af383ccace42b9af",
            "1f63278a72a74ef29fe387d40ba2e23d",
            "38802e15c0714aadbae87a9e6dce93e0",
            "c5fb9a77df654a37953fd489150aa89d",
            "e1570b439f4a4865a0af5b20d298da03",
            "0fb9870e85834e1c86f96f7543512e14",
            "ce67513433d84eadaf6505b978af80aa",
            "f372dbf554a14c4aa7dd26c317eebbff",
            "5d3ee64ca66c42d49a15f5473533a204",
            "04a7173d85534dce8f75b57d24b241c8",
            "87122f81d6114e40ad9c795cdd3b869f",
            "d0e30a609b6046e583dc1555c528dac2",
            "df31e77abd894e959466cc6f7e2dcb82",
            "22e6790be91d45eaa3293061b11eebb8",
            "b1477f23533f4f4ca2e97b5e2a69da2a",
            "445353e34b71421e912367fc08cf3fdc",
            "db0842cb814b444fa658ccd87eb3af23",
            "ad540af99a264153aaba34180bf8557f",
            "98a118ec403247c68fcc38fe78a2531f",
            "ab22a393fb18419fa526d59c6e5384c5"
          ]
        },
        "id": "2O3ip3ra3He3",
        "outputId": "72df881c-f940-4a2f-8061-3cbf71a90410"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddd628f54475406994046cd27030bc2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/34713 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set label counts: Counter({1: 30315, 0: 4398})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f40bd6bed8304a93b7b2760bc81c3047",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3856 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation set label counts: Counter({1: 3374, 0: 482})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04a7173d85534dce8f75b57d24b241c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3359 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set label counts: Counter({1: 2169, 0: 1190})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_labels(dataset):\n",
        "    labels = []\n",
        "    for _, label in tqdm(dataset):\n",
        "        labels.append(label.item())\n",
        "    return Counter(labels)\n",
        "\n",
        "print(\"Train set label counts:\", count_labels(datamodule.train_dataloader().dataset))\n",
        "print(\"Validation set label counts:\", count_labels(datamodule.val_dataloader().dataset))\n",
        "print(\"Test set label counts:\", count_labels(datamodule.test_dataloader().dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbY_kyav3WY6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04a7173d85534dce8f75b57d24b241c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87122f81d6114e40ad9c795cdd3b869f",
              "IPY_MODEL_d0e30a609b6046e583dc1555c528dac2",
              "IPY_MODEL_df31e77abd894e959466cc6f7e2dcb82"
            ],
            "layout": "IPY_MODEL_22e6790be91d45eaa3293061b11eebb8"
          }
        },
        "0fb9870e85834e1c86f96f7543512e14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f63278a72a74ef29fe387d40ba2e23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f372dbf554a14c4aa7dd26c317eebbff",
            "placeholder": "​",
            "style": "IPY_MODEL_5d3ee64ca66c42d49a15f5473533a204",
            "value": " 3856/3856 [01:49&lt;00:00, 37.09it/s]"
          }
        },
        "22e6790be91d45eaa3293061b11eebb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24856f9a1aa1413090eca37245f47792": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ee7ecaeeea4c7d8069813b043bcc0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33cdd44a03a344ecb6ac265d8f58ecfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5fb9a77df654a37953fd489150aa89d",
            "placeholder": "​",
            "style": "IPY_MODEL_e1570b439f4a4865a0af5b20d298da03",
            "value": "100%"
          }
        },
        "38802e15c0714aadbae87a9e6dce93e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "445353e34b71421e912367fc08cf3fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a8e27aa4d4a469fbaf6a7b0197685e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d3ee64ca66c42d49a15f5473533a204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b8761761a0541e6b150d15b4de8e049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "87122f81d6114e40ad9c795cdd3b869f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1477f23533f4f4ca2e97b5e2a69da2a",
            "placeholder": "​",
            "style": "IPY_MODEL_445353e34b71421e912367fc08cf3fdc",
            "value": "100%"
          }
        },
        "8a313f8222214631816864bedb6ba010": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ce5a029ec634b54af383ccace42b9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb9870e85834e1c86f96f7543512e14",
            "max": 3856,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce67513433d84eadaf6505b978af80aa",
            "value": 3856
          }
        },
        "98a118ec403247c68fcc38fe78a2531f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bea896a919b42dab93cd75f679a8a19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da13c1b7c404efa88ac3d2b40f4b91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d554a8c379854e47b930bc657aead223",
              "IPY_MODEL_e66c0970e4f24848bf53e72a54a28fb9",
              "IPY_MODEL_a274e9e768994b20b00bb9959611fc98"
            ],
            "layout": "IPY_MODEL_ac1adc863f3e42dabf351cc4bb97c55b"
          }
        },
        "a274e9e768994b20b00bb9959611fc98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb475a9673c04d4d821b032f9c702c88",
            "placeholder": "​",
            "style": "IPY_MODEL_e421121df89945d2a9cc4bc18bb92912",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "ab22a393fb18419fa526d59c6e5384c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac1adc863f3e42dabf351cc4bb97c55b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad540af99a264153aaba34180bf8557f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae9150ba3b3f4389a6ce2a504bd3e269": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aed39ae258ba4dcfb14f17b28708312a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1477f23533f4f4ca2e97b5e2a69da2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2de770d479f432ab52b74f3cb445fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5858ce3a17c41f18ca559cea532d34d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6eec428cb5242b4b7c143c128636e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c220861f5d0c4e3a88925ff63c0d6638": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_24856f9a1aa1413090eca37245f47792",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 153/153 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:04:04 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.63it/s</span>  \n</pre>\n",
                  "text/plain": "Testing \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 153/153 \u001b[2m0:04:04 • 0:00:00\u001b[0m \u001b[2;4m0.63it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "c5fb9a77df654a37953fd489150aa89d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce67513433d84eadaf6505b978af80aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0b6ba3e0dfa4ead8b61984a24e79b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9fc87297401453cb0d8854d3b66e540",
            "placeholder": "​",
            "style": "IPY_MODEL_ae9150ba3b3f4389a6ce2a504bd3e269",
            "value": " 34713/34713 [16:24&lt;00:00, 34.79it/s]"
          }
        },
        "d0e30a609b6046e583dc1555c528dac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db0842cb814b444fa658ccd87eb3af23",
            "max": 3359,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad540af99a264153aaba34180bf8557f",
            "value": 3359
          }
        },
        "d554a8c379854e47b930bc657aead223": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed39ae258ba4dcfb14f17b28708312a",
            "placeholder": "​",
            "style": "IPY_MODEL_31ee7ecaeeea4c7d8069813b043bcc0c",
            "value": ""
          }
        },
        "d713c474f1504c57a6f815cc965de362": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bea896a919b42dab93cd75f679a8a19",
            "placeholder": "​",
            "style": "IPY_MODEL_b2de770d479f432ab52b74f3cb445fbe",
            "value": "100%"
          }
        },
        "db0842cb814b444fa658ccd87eb3af23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd628f54475406994046cd27030bc2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d713c474f1504c57a6f815cc965de362",
              "IPY_MODEL_f65f95c6f49b4ce8a9aa96c566331e68",
              "IPY_MODEL_d0b6ba3e0dfa4ead8b61984a24e79b85"
            ],
            "layout": "IPY_MODEL_8a313f8222214631816864bedb6ba010"
          }
        },
        "df31e77abd894e959466cc6f7e2dcb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a118ec403247c68fcc38fe78a2531f",
            "placeholder": "​",
            "style": "IPY_MODEL_ab22a393fb18419fa526d59c6e5384c5",
            "value": " 3359/3359 [01:35&lt;00:00, 31.84it/s]"
          }
        },
        "e1570b439f4a4865a0af5b20d298da03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e421121df89945d2a9cc4bc18bb92912": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e66c0970e4f24848bf53e72a54a28fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8761761a0541e6b150d15b4de8e049",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6eec428cb5242b4b7c143c128636e58",
            "value": 0
          }
        },
        "e9fc87297401453cb0d8854d3b66e540": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f372dbf554a14c4aa7dd26c317eebbff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f40bd6bed8304a93b7b2760bc81c3047": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33cdd44a03a344ecb6ac265d8f58ecfe",
              "IPY_MODEL_8ce5a029ec634b54af383ccace42b9af",
              "IPY_MODEL_1f63278a72a74ef29fe387d40ba2e23d"
            ],
            "layout": "IPY_MODEL_38802e15c0714aadbae87a9e6dce93e0"
          }
        },
        "f65f95c6f49b4ce8a9aa96c566331e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5858ce3a17c41f18ca559cea532d34d",
            "max": 34713,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a8e27aa4d4a469fbaf6a7b0197685e2",
            "value": 34713
          }
        },
        "fb475a9673c04d4d821b032f9c702c88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f58758710b410cbcc0321e8a27734d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d0978dada8a4d40abfb3ad342ace9a5",
              "IPY_MODEL_eddeb91ed04f43b085bc110a8770a1b3",
              "IPY_MODEL_0ad43919760a40fdb7b6ceb6cfa8bc11"
            ],
            "layout": "IPY_MODEL_4272e77b8db14078b9a3cfe524a11c83"
          }
        },
        "1d0978dada8a4d40abfb3ad342ace9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6065328ba8664b47bd47647b9b3a26a9",
            "placeholder": "​",
            "style": "IPY_MODEL_613bff1ec61d40f9a7eb164e060c718f",
            "value": "Loading weights: 100%"
          }
        },
        "eddeb91ed04f43b085bc110a8770a1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d2239a53234b528019642cafbe313e",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37768f5ed1974541affb5eab0962a0ff",
            "value": 408
          }
        },
        "0ad43919760a40fdb7b6ceb6cfa8bc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca96a9519bf04702a7baebcbd8d3530f",
            "placeholder": "​",
            "style": "IPY_MODEL_3ec2aae1cb12483bae5cb7a02a8343ea",
            "value": " 408/408 [00:00&lt;00:00, 903.58it/s, Materializing param=vision_model.post_layernorm.weight]"
          }
        },
        "4272e77b8db14078b9a3cfe524a11c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6065328ba8664b47bd47647b9b3a26a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "613bff1ec61d40f9a7eb164e060c718f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d2239a53234b528019642cafbe313e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37768f5ed1974541affb5eab0962a0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca96a9519bf04702a7baebcbd8d3530f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ec2aae1cb12483bae5cb7a02a8343ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
